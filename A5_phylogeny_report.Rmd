---
title: "Comparing models of molecular evolution for phylogenetic analysis of the scale worm family Polynoidae"
author: "Jason Moggridge 1159229"
date: "10/12/2020"
output: pdf_document
highlight: 'kate'
urlcolor: blue
bibliography: polynoid_refs.bib
toc: true
---


<!-- the plan -->

<!-- seqs -->
<!-- filter, sample -> eda fig 1. -->
<!-- align -> dna.bin -->
<!-- basic guide tree (nj) + dist matrix >  -->
<!-- ML phylogeny model testing -> fig2 -->
<!-- anova LRT for comparing models -> ? table? matrix? -->
<!-- dist.topo -> compare multiple models -->
<!-- one tangle gram between decipher and best phangorn or GTR -->

----

This work is available on [github](https://github.com/jmoggridge/6210_project5_phylogeny)

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  cache = TRUE,
	echo = TRUE,
	message = FALSE,
	warning = FALSE
)
options(tinytex.verbose = TRUE)
rm(list = ls())
```

The following software libraries were used in this work:

```{r installs, eval=FALSE, include=FALSE}
# install.packages('tidyverse')
# install.packages('bold')
# if (!requireNamespace("BiocManager", quietly = TRUE))
#     install.packages("BiocManager")
# BiocManager::install("Biostrings")
# install.packages('ape')
# install.packages('DECIPHER')
# install.packages('phangorn')
# install.packages('dendextend')
# install.packages('ggdendro')
# install.packages('rcartocolor')
# install.packages('ggthemes')
# install.packages('patchwork')
```

```{r libraries}
library(tidyverse)
library(bold)
library(Biostrings)
library(ape)
library(DECIPHER)
library(phangorn)
library(dendextend)
library(ggdendro)
library(rcartocolor)
library(ggthemes)
library(patchwork)
```

------

### 1. Introduction

  Phylogenetic analysis is common in biodiversity studies and environmental assessment, however it can be far from clear how to proceed. Not only are there are various phylogenetic marker genes (or combinations thereof) to assess, types of alignment (nucleic acid or protein, symbolic or structural) and methods for estimating phylogeny (distance, maximum-parsimony, maximum-likelihood). In methods based on distance and maximum-likelihood, molecular evolution is modeled as a Markov process (*ie*. memoryless) with parameters for the base frequencies and rates of substitution. More complex models account for different substitution rates and base frequencies (eg, General time reversible). Additional models describe variance in rates across the sequence (+G) and proportion of invariant positions (+I).    
    
   Maximum likelihood-based (ML) phylogenetic clustering methods optimize model parameters to maximize the probability of the data given the model[@Felsenstein1981]. As no model is a perfect representation of nature, we need to apply some bias (*eg* log-likelihood, AIC, BIC) to evaluate the fit of competing models [@Posada2001]. Perhaps this model selection step is unnecessary and we can generally use the most complex model, GTR+I+G, as we are not particularly interested in the distances, but rather the phylogenetic inferences that we make based on them[@Abadi2019].   
    
   In this work, I sought to explore the impact of model choice in whether model testing is worthwhile. Specifically, I wanted to find out whether different distance models would lead to altered phylogenetic trees. For this, I performed model testing to evaluate AIC, BIC and likelihood criteria, pairwise statistical tests of log-likelihood ratios and tree distances, and a visual comparison of two maximum-likelihood phylogenies in a tanglegram. I chose to use cytochrome c oxidase subunit I sequences of Polynoidae as a model dataset. Polynoidae are a large and speciose family of scale worms that have colonized challenging habitats in the deep sea, including sea caves and hydrothermal vents species[@Zhang2017a; @Salazar-Vallejo2015]. New species are consistently found in surveys and determining their phylogenetic relationships to known species is of interest[@Norlinder2012; @Hatch2020a].    

-----

### 2. Polynoid DNA sequence dataset acquisition

```{r eval=FALSE}
# Download BOLD specimen + seq data for taxon 'Polynoidae'
polynoids.bold <- bold::bold_seqspec(taxon = 'Polynoidae')
polynoids.bold <- polynoids.bold %>%
  select(processid, contains('name'), contains('marker'), nucleotides) %>%
  select(-c(trace_names, phylum_name, class_name, subspecies_name,
            marker_codes))
write_rds(polynoids.bold, 'polynoid.raw.rds', compress = 'gz')
```
  
  Polynoidae sequence data were downloaded from the public Barcode of Life Database (BOLD) api on 2020-12-12, using their `bold` package. There were 1850 specimen records for this taxon in the database in total. The data of interest (identifiers, sequences, and taxonomic names) were saved as `polynoid.raw.rds`.     
----

### 3. Selection of cytochrome c oxidase subunit 1 sequences

<!-- 3. Code Section 1 – Data Acquisition, Exploration, Filtering, and Quality Control (25%) -->

```{r tidy and filter}
tidy_bold_data <- function(bold.df, markers){
  # blanks to NA's; strings to factors, except for seqs
  # remove rows missing genus+species names
  bold.df <- bold.df %>%
    mutate(across(where(is.character), ~na_if(.x, ''))) %>%
    mutate(across(where(is.character), as_factor)) %>%
    mutate(nucleotides = as.character(nucleotides))  %>%
    filter(!is.na(genus_name) & !is.na(species_name)) 
  return(bold.df)
}
trim_and_filter_seqs <- function(bold.df, markers, minlen, maxlen, Nthreshold){
  bold.df <- bold.df %>%
    # keep seqs of selected gene; trim N and gaps; 
    # filter to seqs within length range and Ns threshold
    filter(!is.na(nucleotides) & markercode %in% markers) %>%
    mutate(seq = str_remove_all(nucleotides, '\\s|-|^N+|N+$'),
           slen = nchar(seq)) %>%
    filter(slen >= minlen & slen <= maxlen & 
             str_count(seq, 'N')/slen <= Nthreshold)
  return(bold.df)  
}

# read in data & apply filtering steps
polynoids.bold <- read_rds('polynoid.raw.rds')
polynoids.df <- polynoids.bold %>%
  tidy_bold_data() %>%
  trim_and_filter_seqs(markers = 'COI-5P', minlen = 630, maxlen = 680, Nthreshold =  0.02)
# Sample 1 sequence per species for analysis
set.seed(1)
polynoids.sample <- polynoids.df %>%
  group_by(species_name) %>%
  sample_n(1) %>%
  data.frame() %>%
  mutate(seqlabel = paste(genus_name, row_number())) %>%
  mutate(across(where(is.factor), fct_drop)) # drop empty factor levels
```

Only Polynoidae specimens having complete taxonomic information and *cytochrome c oxidase subunit I* (CO1) DNA sequences of appropriate length (630-680 bp), with a low proportion of ambiguous bases (< or = 2%), were retained. This filtered dataset has `r nrow(polynoids.df)` specimens comprised of `r length(unique(polynoids.df$genus_name))` genera, with `r length(unique(polynoids.df$species_name))` species in total. A single representative from each species was chosen at random for alignment and  phylogenetic analysis.

```{r EDA, results = 'hold', fig.height=2, fig.width=6, fig.align='center'}
EDA_plot <- function(bold.df, label) {
  # plot sequence lengths, GC%, species per genus
  a <- ggplot(bold.df, aes(x = slen)) +
    labs(x = 'Sequence length', subtitle = label) +
    geom_histogram() + geom_rangeframe() + theme_tufte()
  b <- bold.df %>%
    mutate(`% GC` = str_count(seq, '[GC]')/slen*100) %>%
    ggplot(aes(x=`% GC`)) + 
    geom_histogram() + geom_rangeframe() + theme_tufte()
  c <- bold.df %>%
    group_by(genus_name) %>%
    summarize(species = length(unique(species_name))) %>%
    ggplot(aes(x=species)) + 
    xlab('Species per genus') +
    geom_histogram() + geom_rangeframe() +theme_tufte()
  return(a+b+c)
}
EDA_plot(polynoids.sample, 
         paste('Sampled data: n =', nrow(polynoids.sample)))

rm(polynoids.bold, polynoids.df, tidy_bold_data, trim_and_filter_seqs, EDA_plot)
```
__Figure 1__. Exploratory analysis of sequence length (l), GC composition (c), and species distribution among genera (r) polynoid *cytochrome c oxidase subunit 1* sequences dataset for analysis (with one sequence per species. 


### 4. Tools for model tests and phylogenetic analysis

This work relied heavily on the `phangorn` package for maximum-likelihood phylogeny construction and model tests. Many tools are available for maximum-likelihood phylogeny, however `phangorn` has a va

Sequence alignments and an alternate ML phylogenetic clustering were done with the package `DECIPHER`[@Wright2016]. Molecular evolution models were tested in maximum likelihood clustering `phangorn::modelTest`. Alignments in `DECIPHER` are fast and accurate, though many other good choices are available, including the popular `muscle` and `clustal` algorithms. Many implementations of hierarchical clustering are available in R; I chose to use the `DECIPHER` package because of it's integration of multiple tools needed for this analysis into a handy R package. The `ape` package was used to perform model-specific distance calculations (using `dist.dna`) as well as tree-topology comparisons (with `dist.topo`.  For visualizations, I used `ggplot2` for plots, as well as `dendextend` to create dendrograms and tanglegrams. Most of these analyses are explained clearly in the package vignettes (see references), however this work extends those by chaining them together for the comparison of phylogenies with testing and other visualizations.


<!-- Silhouette plots were created with... rpartplot -->

<!-- 4. Main Software Tools Description (1 paragraph) (5%) -->
<!-- 
Provide a short written description (1 paragraph) about the main software tool you will be using to answer your main question. 
Why did you make this choice? What are the expected strengths and weaknesses of the tool you chose? Did you consider any alternatives? Cite the authors of the tool you used (you can cite the package itself plus the relevant associated publication, if available). If you are conducting a methodological project involving a comparison of tools, you might briefly describe two main tools in this section. Otherwise, you will typically describe one main software tool. -->
<!-- Also, in this section, make it clear how you built upon existing vignettes for conducting your project. -->

### 5. Model testing and phylogenetic Analysis

<!-- Code Section 2 – Main Analysis (25%) --><!-- explore the impact of methodological choices upon results. --> <!-- max 3 figures -->

Alignment of sequences using `DECIPHER`

```{r alignment}
do_alignment <- function(sample.df, names_vector, browse=FALSE, verbose = FALSE){
  # Format and label seqs, reorient reverse complements, align
  seqs <- Biostrings::DNAStringSet(sample.df$seq)
  names(seqs) <- names_vector
  seqs <-  DECIPHER::OrientNucleotides(seqs, verbose = verbose)
  seqs.aligned <- DECIPHER::AlignSeqs(seqs, verbose = verbose)
  if (browse==TRUE){
    BrowseSeqs(seqs.aligned)
    }
  return(seqs.aligned)
}
# perform alignment and hierarchical clusterings
polynoids.align <- do_alignment(polynoids.sample, polynoids.sample$seqlabel)
polynoids.bin <- as.DNAbin(polynoids.align)
rm(do_alignment)
```


Model Testing with `Phangorn`

```{r phangorn model test, message=FALSE}
# need phyDat format for test
polynoids.phy <- as.phyDat(polynoids.bin)
# calculate dist, make basic tree, then test subs. models
polynoids.dist <- phangorn::dist.ml(polynoids.phy, model='JC69')
polynoids.nj <- NJ(polynoids.dist)
model_test <- phangorn::modelTest(polynoids.phy, polynoids.nj, control = pml.control(trace=0))
```


```{r best model in test, include=FALSE}
best_BIC <- model_test %>% filter(BIC == min(model_test$BIC)) %>% pull(Model)
best_AICc <- model_test %>% filter(AICc == min(model_test$AICc)) %>% pull(Model)
best_logLik <- model_test %>% filter(logLik == max(model_test$logLik)) %>% pull(Model)
```


```{r get phangorn phylo models and do tests}
get_all_models <- function(model_test_obj){# get models from phangorn modelTest output
  # adapted from https://rdrr.io/cran/phangorn/man/modelTest.html
  extract_model <- function(name, env){ # retrieves model from model test output
    mod <- get(name, env)
    mod <- eval(mod, env=env)
  }
  # extract models from model test env object using names list 
  tests.env <- attr(model_test_obj, "env")
  model.names <- ls(env=tests.env)[2:25]
  models <- lapply(model.names, extract_model, tests.env)
  names(models) <- model.names
  return(models)
}
get_models_pw_df <- function(models){ # makes long-form df of upper triangle of models' pairwise matrix 
  m.names <- names(models)
  m.len <- length(m.names)
  models.df <- tibble(
    name1 = rep(m.names, each = m.len),
    name2 = rep(m.names, times = m.len),
    model1 = rep(models, each = m.len),
    model2 = rep(models, times = m.len)
  ) %>%
    # keep only 'upper triangle' if df was sq matrix
    mutate(index1 = match(name1, m.names),
           index2 = match(name2, m.names)) %>%
    filter(!index2 <= index1) %>%
    select(-index1, -index2)
  return(models.df)
}
##
# get all the models and then perform stats tests
models.pairwise.df <- get_models_pw_df(get_all_models(model_test))  %>%
  # rowwise because doing row ops with list columns
  rowwise() %>%
  # perform pairwise logLik ratio tests
  mutate(anova = list(anova(model1, model2)))  %>%
  # grab logLik difference and p-values from LRT anova
  mutate(anova.loglikdif = pluck(pluck(anova, 4), 2),
         anova.pr = pluck(pluck(anova, 5), 2),
         anova.pr = ifelse(is.nan(anova.pr), 1, anova.pr)) %>%
  # grab phylo trees from model objs
  mutate(tree1 = list(pluck(model1, 'tree')), 
         tree2 = list(pluck(model2, 'tree'))) %>%
  # compute tree dists: RobinsonFoulds, weightedRF, branch-score diff, path diff
  mutate(
    RF.dist = phangorn::RF.dist(tree1, tree2, check.labels = TRUE),
    wRF.dist = phangorn::wRF.dist(tree1, tree2, check.labels = TRUE),
    KF.dist = phangorn::KF.dist(tree1, tree2, check.labels = TRUE),
    path.dist = phangorn::path.dist(tree1, tree2, check.labels = TRUE)
  ) %>%
  ungroup()

glimpse(models.pairwise.df)
summary(models.pairwise.df$RF.dist)
summary(models.pairwise.df$wRF.dist)
summary(models.pairwise.df$KF.dist)
summary(models.pairwise.df$path.dist)
models.pairwise.df %>% filter(name2 == 'HKY+G+I' & name1 == 'GTR+G+I') %>% select(contains('dist'))

models.df <- models.pairwise.df %>%
  select(name1, model1, tree1) %>%
  group_by(name1) %>%
  filter(row_number() == 1)
```




<!-- The following models of molecular evolution tested with phangorn: -->
<!-- - JC: One parameter for all substitutions; equal base frequencies (Jukes and Cantor 1969). -->
<!-- - F81: Variable base frequencies, equal substitution rates (Felsenstein 1981) -->
<!-- - GTR: General time-reversible: variable bases, symetric substitution matrix  (Lanave et al. 1984) -->
<!-- - HKY: Hasegawa-Kishino-Yano: One parameter each for transitions and tranversions, with variable base frequencies (Hasegawa et. al. 1985) -->
<!-- - K80: One parameter each for transitions and tranversions, with equal base frequencies (Kimura 1980) -->
<!-- - SYM: Symmetrical substititions with equal base frequencies (Zharkikh 1994) -->



```{r ML clustering with decipher}
## Maximum-likelihood hierarchical clustering
clusters.ML <- DECIPHER::IdClusters(
  myXStringSet = polynoids.align,
  myDistMatrix = DistanceMatrix(polynoids.align, type='dist'),
  method = 'ML', 
  cutoff = 0.2, showPlot = FALSE,
  type = "both", verbose = TRUE)

# Distance-based clustering using Jukes Cantor model (basic phylogeny)
clusters.JC <- DECIPHER::IdClusters(
  myXStringSet = polynoids.align,
  myDistMatrix = dist.dna(x = polynoids.bin, model = 'JC',
             as.matrix = FALSE, pairwise.deletion = TRUE),
  model = 'JC', method = 'NJ',
  cutoff = 0.17, showPlot = FALSE,
  type = "both", verbose = FALSE)
```


```{r}

# logLik ratio test: DECIPHER ML phylo against best phangon ML phylo
class(clusters.ML[[2]])
decip.ML.phyl <- as.phylo(clusters.ML[[2]])
class(decip.ML.phyl)

phang.ML.phyl <- models.df %>% 
  filter(name1 == "HKY+G+I") %>% 
  pull(tree1) %>% pluck(1)
class(phang.ML.phyl)

treedist(decip.ML.phyl, phang.ML.phyl)
dist.topo(decip.ML.phyl, phang.ML.phyl)
RF.dist(decip.ML.phyl, phang.ML.phyl)
wRF.dist(decip.ML.phyl, phang.ML.phyl)

# phangorn: HKY loglik = -20741.39
model_test %>% filter(Model=="HKY+G+I") %>% pull(logLik)
# decipher: TN93+G4 -> -20840
# decip.ML.phyl <- 
# 
# phang.ML.phyl$  

# anova(, phang.ML.phyl)
```


In all criteria, HKY+I+G was the best performing model, however only by a small margin compared to GTR+I+G.
I performed anovas using the `phangorn` implementation for log-likelihood ratio tests. The difference between HKY+I+G and GTR+I+G was not significant, however difference between the simplest models (non +I+G) and those with I+G parameters were all significant.

TN93+G4 model parameters:
  - Frequency(A) = 0.249
  - Frequency(C) = 0.218
  - Frequency(G) = 0.170
  - Frequency(T) = 0.364
  - Rate A <-> G = 2.113
  - Rate C <-> T = 4.417
  - Transversion rates = 1
  - Alpha = 0.502

```{r include=FALSE}
rm(polynoids.align)
```

I performed hierarchical clustering with various models (JC, K80, TN93)
I also did a maximum-likelihood clustering of the sequences to compare with the default settings. 

### 6. Figures

<!-- 6. Quality of Visualizations (20%) -->
<!-- Throughout, ensure that your figures are clear and well labeled. Even for simple figures, such as histograms, ensure that you have accurate, informative axis labels. Also, consider readability, visual appeal, and accessibility. Use well-differentiated colours, and avoid relying upon the red-green spectrum to convey scientifically important information. Remember, you can consider using a combination of colour and symbol/pattern to convey your meaning. The grade in this section is based upon quality and novelty, not having the maximum permissible number of figures. You should have a total of 4-6 figures for your project (excluding the bonus section, should you choose to complete that section). -->


```{r model test plot, fig.align='center', fig.height=3.5, fig.width=4}
model_test_plot <- model_test %>%
  select(Model, AICc, BIC, logLik, df)  %>%
  pivot_longer(AICc:df) %>%
  mutate(name = as_factor(name)) %>%
  ggplot() + 
  geom_point(aes(x=Model, y=value, colour = name)) + 
  labs(x = '', y = '') +
  facet_grid(name~., scales = 'free_y') + 
  scale_color_carto_d() +
  theme_light() +
  theme(legend.position = 'none', 
        axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5),
        axis.text.y = element_text(size = 7)
  )
# plotted in 6. Results and discussion
model_test_plot
```


<!-- ```{r model test plot2, fig.align='center', fig.height=3.5, fig.width=4} -->
<!-- model_test_plot2 <- model_test %>% -->
<!--   select(Model, AICc, BIC, logLik, df) %>% -->
<!--   pivot_longer(AICc:df) %>% -->
<!--   mutate(name = as_factor(name), -->
<!--          score2 = ifelse(Model %in% c('GTR+I+G', 'HKY+I+G'), -->
<!--                          value, NA), -->
<!--          name2 = ifelse(Model %in% c('GTR+I+G', 'HKY+I+G'), -->
<!--                          Model, NA)) %>% -->
<!--   ggplot() +  -->
<!--   geom_density(aes(x=value, colour = name)) +  -->
<!--   # geom_vline(aes(x=score2)) + -->
<!--   labs(x = '', y = 'density') + -->
<!--   facet_wrap(~name, ncol=1, scales = 'free') +  -->
<!--   scale_color_carto_d(palette = 2) + -->
<!--   theme_light() +theme(legend.position = 'none') -->
<!-- model_test_plot2 -->
<!-- ``` -->
__Figure 2__. Testing of all DNA substitution models (JC, F81, K80, HKY, TrN, TPM, K81, TIM, TVM, SYM, GTR) with and without added site-specificity (G, I) for the polynoid CO1 sequences, using `phangorn::modelTest`. The AIC, BIC and log likelihood scores (y-axis) are shown for each model (x-axis), where smaller AICc and BIC scores and larger log likelihood scores indicate better fit. The degrees of freedom for each model are included (df). 


```{r fig.width=8, fig.height=7}
# Create heatmap for log-likelihood difference
a <- ggplot(models.pairwise.df, aes(y=name2, x=name1, fill=anova.loglikdif)) +
  geom_tile(na.rm = TRUE, ) +
  theme_light() +
  scale_fill_viridis_c(option='C') +
  labs(x='', y='', 
       fill='difference in \nlog-likelihood:\nll(x) - ll(y)') +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5),
        legend.position = 'left')
# Create heatmap for p-values
b <- ggplot(models.pairwise.df, aes(y=name2, x=name1, fill=anova.pr)) +
  geom_tile(na.rm = TRUE) +
  theme_light() +
  scale_fill_viridis_c(option='D',direction = -1) +
  labs(x='', y='',
       fill='p-value') +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5),
        legend.position = 'top')
c <- ggplot(models.pairwise.df, aes(y=name2, x=name1, fill=wRF.dist)) +
  geom_tile(na.rm = TRUE) +
  theme_light() +
  scale_fill_viridis_c(option='A',direction = 1) +
  labs(x='', y='',
       fill='wieghted RF distance') +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5),
        legend.position = 'left')
(a+b)/(c+plot_spacer())

```
__Figure 3__. Heatamaps for the difference in log-likelihood between each pair of models (left) and associated p-values (right) from pairwise likelihood ratio tests of all models tested using `phangorn`.


```{r tanglegram JC v ML, fig.align='center', fig.width=8, fig.height=6}
get_entang_val <- function(dend1, dend2){
  # gets the entanglement score for two dendrograms
  dend1 <- match_order_by_labels(dend1, dend2) 
  dend.list <- dendlist(dend1, dend2)
  entangle.val <- entanglement(dend.list) # calculate entanglement
  return(entangle.val)
}

make_tanglegram <- function(dend1, dend2, title1, title2){
  # makes a tanglegram from 2 dendrograms after orienting leaves
  dend1 <- match_order_by_labels(dend1, dend2)
  dend.list <- dendlist(
    dend1 %>% set('labels_cex', 0.65) %>% set("branches_lwd", 1),
    dend2 %>% set('labels_cex', 0.65) %>% set("branches_lwd", 1)
    )
  gram <- dend.list %>% 
    # need dendext function here, not phytools
    dendextend::untangle() %>% 
    tanglegram(
      main_left = title1,
      main_right = title2,
      just_one = TRUE,
      columns_width = c(6,2,6),
      left_dendo_mar = c(2, 2, 2, 6),
      right_dendo_mar = c(2, 6, 2, 2),
      # common_subtrees_color_branches = TRUE,
      # common_subtrees_color_lines = TRUE,
      # highlight_distinct_edges = FALSE
      match_order_by_labels = TRUE
      )
}

tang_val_JC_ML <- get_entang_val(clusters.JC[[2]], clusters.ML[[2]])
tang_val_JC_ML
tangle_JC_ML <- make_tanglegram(clusters.JC[[2]], clusters.ML[[2]], 'JC distance based',  'TN93 + G maximum likelihood' )
```

```{r}
# library(phylogram)
# dend.list <- dendlist(
#    phylogram::as.dendrogram.phylo(fitJC$tree) %>%
#       set('labels_cex', 0.65) %>% set("branches_lwd", 1),
#    phylogram:: as.dendrogram.phylo(fitGTR$tree) %>%
#       set('labels_cex', 0.65) %>% set("branches_lwd", 1)
#     ) %>%
#   dendextend::untangle() %>% 
# # Make tanglegram
#   tanglegram(
#     match_order_by_labels = TRUE,
#     just_one = TRUE,
#     color_branches = TRUE,
#     columns_width = c(6, 1, 6),
#     left_dendo_mar = c(2, 2, 2, 6),
#     right_dendo_mar = c(2, 6, 2, 2)
#   )
```

```{r tanglegram JC v ML2, fig.align='center', fig.width=8, fig.height=6}
dend.list <- dendlist(
    clusters.JC[[2]] %>% set('labels_cex', 0.65) %>% set("branches_lwd", 1),
    clusters.ML[[2]] %>% set('labels_cex', 0.65) %>% set("branches_lwd", 1)
    ) %>%
  dendextend::untangle() %>% 
# Make tanglegram
  tanglegram(
    match_order_by_labels = TRUE,
    just_one = TRUE,
    columns_width = c(6, 1, 6),
    left_dendo_mar = c(2, 2, 2, 6),
    right_dendo_mar = c(2, 6, 2, 2)
  )
```

```{r}
ape::dist.topo(as.phylo(clusters.JC[[2]]),
               as.phylo(clusters.ML[[2]]))
```

<!-- The topological distance is defined as twice the number of internal branches defining different bipartitions of the tips (Robinson and Foulds 1981; Penny and Hendy 1985). Rzhetsky and Nei (1992) proposed a modification of the original formula to take multifurcations into account. -->

<!-- The branch length score may be seen as similar to the previous distance but taking branch lengths into account. Kuhner and Felsenstein (1994) proposed to calculate the square root of the sum of the squared differences of the (internal) branch lengths defining similar bipartitions (or splits) in both trees. -->
<!-- Two methods are available: the one by Penny and Hendy (1985, originally from Robinson and Foulds 1981), and the branch length score by Kuhner and Felsenstein (1994). The trees are always considered as unrooted. -->



### 7. Supplemental 

<!-- Bonus Section (Optional) (5%) -->
<!-- This section can contain whatever you want! This is your chance to do something of interest to you, which is related to your overall topic, but which didn’t fit into the mandatory sections. -->
<!-- An example of a topic that could go here would be benchmarking your analysis for computational speed and/or for accuracy (against comparator tools). Or, you could include supplementary statistical testing (e.g. testing whether your results are sensitive to your analytical choices in your main analysis section). You could also include supplementary visualizations of your choosing. -->
<!-- The maximum length of this section is 2 pages of your final PDF assignment. Any content above the two-page limit for this section will not be graded. This could consist of prose, commented code, statistical results, and/or visualizations (your choice). -->
<!-- Tip: Please note that the credit weighting associated with this section is small. So, I suggest ensuring that you have completed a high-quality project for all of the other sections before preparing anything for this section. -->
<!-- Note: The presence of this section means that a grade for Assignment #5 could hypothetically go above 100% (to a maximum of 105%). However, overall course grades are capped at 100% maximum. -->


Saturation plots:
P-distance and Kimura 2-parameter distance.  
Transitions and transversions as a function of distance.

```{r supPlot1, fig.height=2.5, fig.width=5, fig.align='center'}
distVector <- function(model, dnabin){
  # return numeric vector of the upper triangle of the distance matrix
  dist <- dist.dna(x = dnabin,
                   model = model,
                   as.matrix = FALSE,
                   pairwise.deletion = TRUE)
  return(as.numeric(dist))
}

# Molecular evolution analysis ----
# create a df with all the distance measures as columns
dist.df <- tibble(model = c('raw','jc69','N', 'k80', 'tn93', 'gg95', 'TS', 'TV')) %>%
  mutate(data = lapply(model, function(x) distVector(x, polynoids.bin))) %>%
  pivot_wider(names_from = 'model', values_from = 'data') %>%
  unnest(cols = raw:TV)

glimpse(dist.df)

# plot p-distance ~ k80 distance
raw_k80.plot <- dist.df %>%
  ggplot(aes(x=k80, y=raw)) + 
  geom_point(alpha = 0.5, size = 0.5, pch = 1) +
  # add diagonal line
  geom_path(
    data = data.frame(x = seq(0, 1, 0.05), y = seq(0, 1, 0.05), group = factor('group')),
    aes(x = x, y = y, group = group), alpha = 0.7, lty = 2) +
  theme_classic() +
  xlim(c(0, 0.72)) +
  ylim(c(0, 0.45)) +
  labs(x = 'K2P distance', y = 'p-distance (raw)',
       subtitle = 'Saturation plot:\n distances of Polychaete CO1 sequences')

# plot transitions and transversions ~ k80 distance
ts_tv.plot <- dist.df %>%
  select(k80, TS, TV) %>%
  # manipulate table into long-form
  pivot_longer(cols=c(TS, TV),
               names_to = 'Substitution', values_to = 'Proportion') %>%
  # create scatterplot w smooth fits
  ggplot(aes(x = k80, y = Proportion, color = Substitution, group = Substitution)) +
  geom_point(size=0.04, alpha = 0.3) +
  geom_smooth(method = 'loess', formula = 'y~x', se=FALSE) +
  theme_classic() +
  scale_color_carto_d('Type') +
  guides(
    colour = guide_legend(override.aes = list(size=5, alpha=1, pch=15))
    ) +
  labs(
    x = 'K2P distance',
    y = 'Substiutions',
    title = '',
    subtitle = 'Transitions and transverions by K2P distance\n in Polynoidae COI sequences'
    )
raw_k80.plot + ts_tv.plot
rm(raw_k80.plot, ts_tv.plot, dist.df)
```

I attempted to align translated sequences, however the results were not impressive. The alignment has several sequences that did not align at all. I suspect that the `aligntranslation` algorithm could not find the correct reading frame automatically and that to do so would require manually trimming sequences to setting the reading frame to begin at a codon; this did not seem feasible to do within the scope of the project. As such, left this out of the analysis.

```{r eval = FALSE}
# translated alignment performs really poorly
align.translated <- DECIPHER::AlignTranslation(DNAStringSet(polynoids.sample$seq), verbose = FALSE)
# BrowseSeqs(align.translated)
```


Comparing distance-based phylogenies in tanglegrams (JC, K80, TN93)

```{r distance-based phylog tanglegrams, eval=FALSE, include=FALSE, fig.align='center', fig.width=8, fig.height=6}

do_clustering <- function(dnabin, model, threshold, algo){
  # performs h.clustering w chosen model, algorithm, & threshold
  DECIPHER::IdClusters(
    dist.dna(x = dnabin, model = model,
             as.matrix = FALSE, pairwise.deletion = TRUE),
    method = algo, cutoff = threshold, verbose = FALSE,
    showPlot = FALSE, type = "both")
} 

# Clustering by three models JC (jc69), K2P (k80), and TN93
models <- c('jc69', 'k80', 'tn93')
clusters <- lapply(models, function(x) do_clustering(polynoids.bin, x, 0.2, 'NJ'))
names(clusters) <- models
dendros <- lapply(clusters, '[[', 2)
names(dendros) <- models

get_entang_val <- function(dend1, dend2){
  # gets the entanglement score for two dendrograms
  dend1 <- match_order_by_labels(dend1, dend2) 
  dend.list <- dendlist(dend1, dend2)
  entangle.val <- entanglement(dend.list) # calculate entanglement
  return(entangle.val)
}
make_tanglegram <- function(dend1, dend2, title1, title2){
  # makes a tanglegram from 2 dendrograms after orienting leaves
  # dend1 <- match_order_by_labels(dend1, dend2) 
  dend.list <- dendlist(
    dend1 %>% set('labels_cex', 0.55) %>% set("branches_lwd", 1),
    dend2 %>% set('labels_cex', 0.55) %>% set("branches_lwd", 1)
    )
  gram <- dend.list %>% dendextend::untangle() %>% # need dendext function
    tanglegram(
      main_left = title1,
      main_right = title2,
      just_one = TRUE,
      columns_width = c(5,1,5),
      left_dendo_mar = c(2, 2, 2, 4),
      right_dendo_mar = c(2, 4, 2, 2),
      match_order_by_labels = TRUE,
      common_subtrees_color_branches = TRUE,
      highlight_distinct_edges = FALSE) 
}
tang_val_K80_JC <- get_entang_val(dendros[[2]], dendros[[1]])
tang_val_TN93_JC <- get_entang_val(dendros[[3]], dendros[[1]])
tang_val_K80_TN93 <- get_entang_val(dendros[[2]], dendros[[3]])
par(mfrow = c(1,3))
tangle_K80_JC <- make_tanglegram(dendros[[2]], dendros[[1]], 'K80','JC')
tangle_TN93_JC <- make_tanglegram(dendros[[3]], dendros[[1]], 'TN93', 'JC')
tangle_K80_TN93 <- make_tanglegram(dendros[[2]], dendros[[3]], 'K80', 'TN93')

# library(phytools)

class(dendros[[1]])
names(dendros)
phylos <- lapply(dendros, as.phylo)
# phylos <- phytools::as.multiPhylo(phylos[[1]], phylos[[2]], phylos[[3]])
# class(phylos)
RH_JC_k80 <- ape::dist.topo(phylos[[1]], phylos[[2]], method = 'PH85')
RH_JC_tn93 <- ape::dist.topo(phylos[[1]], phylos[[3]], method = 'PH85')
RH_k80_tn93 <- ape::dist.topo(phylos[[2]], phylos[[3]], method = 'PH85')
score_JC_k80 <- ape::dist.topo(phylos[[1]], phylos[[2]], method = 'score')
score_JC_tn93 <- ape::dist.topo(phylos[[1]], phylos[[3]],  method = 'score')
score_k80_tn93 <- ape::dist.topo(phylos[[2]], phylos[[3]],  method = 'score')
```

### 8. Results and Discussion
<!-- Result + Discussion section: -->
<!-- o Paragraph 1: Return to your original question. What is the answer to your question? What did you discover? Were your results as expected or not? -->
In this project, I...
<!-- o Paragraph 2: Briefly describe any key caveats of your study. For example, are the conclusions that can be drawn limited by sample size or any other concerns? Were there biases in data availability that could have impacted your project? -->
Only one dataset was used and my findings may not generalize to other sets of sequences. 

Simulated data with known topology and rates of substitution might be better suited for these analyses (as was done in Abadi et al. 2019), though I was interested in the model testing process for a given dataset of interest. 
Only DNA-sequence based phylogenies were compared, though CO1 protein sequences might be preferable for building the polynoid phylogenies.
I took a single sequence as a representative, though it would have been preferable to create a consensus for each species (eg. usng `DECIPHER::IdConsensus`).

While the actual phylogeny itself was not the subject of study, it should be noted that BOLD data may be erroneously labeled in terms of taxonomy.

My results largely indicated that most parameter-rich models produce very similar phylogenies. When datasets are large and model testing would be time-consuming, I would agree that model testing generally seems unnecessary. 
<!-- o Paragraph 3: What would be the next steps for this research? What would you do next if you had more time and if you were going to develop this work into a larger project? Did your results reveal any interesting preliminary findings that would be worthy of follow-up study? -->
<!-- Guidelines: Please see introduction for length guidelines for written paragraphs. -->
<!-- Tip: I suggest that you consider citing 2-4 references in your discussion section to help with interpretation of your results. You may cite references that you also cited in your introduction. -->
<!-- Tip: At the end, I also encourage you to add an additional short paragraph reflecting upon the process of completing this assignment. What did you learn through completing your project? What lessons will you take forward in your future coursework and career? Reflection can help us to solidify our learning and help us to act upon what we have learned in the future. This additional, optional paragraph is not included in the 3-paragraph length limit for this section. -->

A model that treats each substitution differently is more likely to accurately represent evolutionary processes; for example, cytosine deamination, leading to a C to T substitution, is particularly common. However, parameter estimates from maximum likelihood optimization will have greater error as the number of parameters increases. This may be important to consider if the number of sequences is small and parameter estimates are not as precise. In the TN93 model chosen in ML clustering of polynoid CO1 sequences, the estimate for C-T transitions (4.5) was more than double that of A-G transitions (2.1)


Maximum-likelihood clustering was performed and the model selected (having the lowest BIC in this case) was TN93+G, which fit better than the HKY model chosen by the earlier model testing with `phangorn`. Annoyingly, the `DECIPHER` does not have an implementation of GTR for comparison.


In the model test using `phangorn` however, the HKY+G+I model had the lowest Aikake information criterion with correction for small samples (AICc) and Bayesian information criterion (BIC), as well as the greatest log likelihood. Overall, the inclusion of the variation among sites (+G), and static sites (+I) into the model had more impact that differences between substitution models.

Augmented models account for the substitution rate variance among sites: '+G' indicates inclusion of gamma-distributed rate variation among sites; '+I' allows for a proportion of static sites.

Using the `dist.topo` metric (from `ape`) to compare tree by their topological distances (ie. Robinson-Foulds distance),
<!-- I found that the JC and TN93 models produced the most similar trees , while K2P and TN93 models produced the most disparate trees. Branch-length scoring produced similar results. -->





----

### 9. Acknowledgements
<!-- 9. Acknowledgements (section expected to be present for academic integrity) -->
<!-- If you received project tips from others, include that information in this section. Briefly, indicate who you talked to, the nature of the advice, and how this impacted your project. You may speak to other class members and the course instructors. It is NOT permitted to complete the assignment for someone else or to copy/paste blocks of code from others. If someone helped you to get unstuck when you were facing an error message, then indicate who and what you learned from this. (To clarify: You ARE allowed to talk to others, but you are NOT permitted to let them fix the problem for you without you actually understanding what is going on. Write about: What was causing the error message, and what did you learn during the process of obtaining help to fix it?) -->
In preparing this work, I found the following tutorials most helpful:

[The art of multiple sequence alignment in R by E.S. Wright](https://www.bioconductor.org/packages/release/bioc/vignettes/DECIPHER/inst/doc/ArtOfAlignmentInR.pdf)

[Introduction to `dendextend` by T. Galili](https://cran.r-project.org/web/packages/dendextend/vignettes/dendextend.html)

[Estimating phylogenetic trees with phangorn by K.P. Schliep](https://cran.r-project.org/web/packages/phangorn/vignettes/Trees.pdf)

[Genetic data analysis using R: introduction to phylogenetics by T. Jombart](http://adegenet.r-forge.r-project.org/files/MRC-session2-tuto.1.3.pdf)

The chapter 'Phylogeny Estimation' in  "Analysis of Phylogenetics and Evolution with R" by the `ape` author E. Paradis (available through the Guelph library), was particularly helpful for basic aspects of distance-based and maximum likelihood- based phylogeny methods.

Last but not least, I would like to thank Dr. Sarah Adamowicz and Jacqueline May for the advice and support they provided, and my 6210 classmates for various inspirations.


### 10. References

*NB: Any articles not available through the University of Guelph subscriptions were shamelessly pirated through [sci-hub.tw](https://scihubtw.tw/)*
<!-- references automatically inserted here from the bib file `polynoid_refs.bib` -->

<!-- 10. References (grade credit for this section is incorporated into Intro and Discussion grades) -->
<!-- If you cite any sources from the scientific literature, include them here in your reference list. In total for Assignment #5, I suggest consulting and citing 3-6 papers from the literature to help you to develop your idea and/or interpret your results. Ten papers from the literature is the hard maximum for citations, reflecting that you have other assignments and commitments and to encourage some academics/life balance. You may use any of the papers posted to CourseLink or other literature relevant for your project. Additional citations for vignettes, other tutorials, -->
<!-- 9 -->
<!-- StackOverflow posts, etc., are not included in the 10-reference limit. You must cite all such sources. -->
<!-- You would include scientific references as an in-text citation in the relevant sentence of your assignment, i.e. introduction or discussion (e.g. Xu et al. 2020). Also, list the full reference here at the end. If you used any specific online tutorials or a specific StackOverflow posting, for example, you must also include those here. -->
<!-- You should choose a consistent format for your reference list. If you do not already have a preferred format, then I recommend using a simple format such as the following (which includes authors, year, article title, journal name, volume, and page numbers). Your reference list should be ordered by the last name of the first author of each article. Example: -->
<!-- Smith AB, Jones CD, and Zhou EF. 2019. The title of the journal article goes here. Journal Name Goes Here, 25: 131-140. -->




<!-- ```{r modify dendrograms, include=FALSE, fig.height=6} -->
<!-- fix_dendrogram <- function(dendro, template){ -->
<!--   dendro <- dendro %>% -->
<!--     match_order_by_labels(., template) %>% -->
<!--     set('labels_cex', 0.6) %>% -->
<!--     set("branches_lwd", 0.5) -->
<!--   dendro <- as.ggdend(dendro) -->
<!-- } -->
<!-- dendrograms <- lapply(dendros, fix_dendrogram, dendros[[1]]) -->
<!-- # par(mfrow=c(1,3)) -->
<!-- lapply(dendrograms, ggplot, horiz=TRUE) -->
<!-- ``` -->



<!-- ```{r include=FALSE} -->
<!-- # k80 -->
<!-- x <- dendros[[2]] %>% set('labels_cex', 0.7) %>% set("branches_lwd", 1) -->
<!-- # JC69 -->
<!-- y <- dendros[[1]] %>% set('labels_cex', 0.7) %>% set("branches_lwd", 1) -->
<!-- dend_diff(x,y)  -->
<!-- ``` -->





<!-- Maximum-likelihood tree construction with `Phangorn` -->
<!-- ```{r message=FALSE, warning=FALSE} -->
<!-- ## Tree construction with Phangorn -->
<!-- # create base tree w JC model -->
<!-- fit <- pml(polynoids.nj, polynoids.phy) -->
<!-- fitJC <-  optim.pml( -->
<!--   fit, optNni = TRUE, optBf = TRUE, optQ = TRUE,  -->
<!--   control = pml.control(trace = 0)) -->
<!-- fitJC <- optim.pml(fitJC, optNni=TRUE, -->
<!--                    control = pml.control(trace=FALSE)) -->
<!-- # create a tree JC+I+G model -->
<!-- # optimize site variance + % invariant (+I+G params) -->
<!-- fitJC_IG <- update(fitJC, k=4, inv=.2) -->
<!-- fitJC_IG <- optim.pml(fitIG, optGamma=TRUE, optInv=TRUE, -->
<!--                     control = pml.control(trace = 0)) -->
<!-- # fit GTR+I+G tree + optimize model params -->
<!-- fitGTR <- optim.pml( -->
<!--   fitIG, model = 'GTR', optGamma=TRUE, optInv=TRUE, -->
<!--   optNni=TRUE, optBf=TRUE, optQ=TRUE,optEdge = TRUE,  -->
<!--   optRate = TRUE, control = pml.control(trace = 0))  -->
<!-- # fit HKY+I+G tree + optimize model params -->
<!-- fitHKY <- optim.pml( -->
<!--   fitIG, model = 'HKY', optGamma=TRUE, optInv=TRUE, -->
<!--   optNni=TRUE, optBf=TRUE, optQ=TRUE,optEdge = TRUE, -->
<!--   optRate = TRUE, control = pml.control(trace = 0))  -->
<!-- # check scores -->
<!-- fitJC -->
<!-- fitGTR -->
<!-- fitHKY -->
<!-- ``` -->


```{r}
# 
# x <- anova(models[['F81']], models[['GTR']])
# anova(models[['K80']], models[['GTR']])
# anova(models[['K80+I']], models[['F81']])
# anova(models[['GTR']], models[['GTR+G+I']])
# anova(models[['HKY']], models[['HKY+G+I']])
# anova(models[['HKY+G+I']], models[['GTR+G+I']])
```



<!-- #### Silhouette\ -->
<!-- Calculate silhouette index to evaluate internal validity -->
<!-- ```{r Silhouette Index, results = "hold"} -->
<!-- # #Calculate Silhouette summary for gene1 -->
<!-- # silhouette_gene1 <- silhouette (unlist(gene1_clusters[[1]]),dmatrix = gene1_matrix) -->
<!-- # summary.silhouette_gene1<-summary(silhouette_gene1) -->
<!-- # #Output silhouette summary -->
<!-- # sprintf("Silhouette summary for %s",gene1) -->
<!-- # summary.silhouette_gene1 -->
<!-- ``` -->

<!-- Plot Silhouette Analysis -->
<!-- ```{r Silhouette Plot, results = "hold"} -->
<!-- # #Plot silhouette scores for gene1 -->
<!-- # fviz_silhouette(silhouette_gene1, label=FALSE,print.summary=TRUE,xlab="Cluster",main=sprintf("Silhouette Analysis for Clustering on %s Nucleotide Sequences", gene1),submain=sprintf("Clustering Method: %s; Model of DNA Evolution: %s",clustering.method,chosen.model),palette=c("#660000","purple","orange","blue")) -->
<!-- ``` -->
