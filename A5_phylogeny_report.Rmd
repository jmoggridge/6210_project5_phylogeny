---
title: "Comparing models of molecular evolution for phylogenetic analysis of the scale worm family Polynoidae"
author: "J Moggridge"
date: "10/12/2020"
output: pdf_document
highlight: kate
urlcolor: blue
bibliography: polynoid_refs.bib
toc: true
---

This work is available on [github](https://github.com/jmoggridge/6210_project5_phylogeny)

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  cache = TRUE,
	echo = TRUE,
	message = FALSE,
	warning = FALSE
)
options(tinytex.verbose = TRUE)
```

The following software libraries were used in this work:

```{r installs, eval=FALSE, include=FALSE}
# install.packages('tidyverse')
# install.packages('bold')
# if (!requireNamespace("BiocManager", quietly = TRUE))
#     install.packages("BiocManager")
# BiocManager::install("Biostrings")
# install.packages('ape')
# install.packages('DECIPHER')
# install.packages('phangorn')
# install.packages('dendextend')
# install.packages('ggdendro')
# install.packages('rcartocolor')
# install.packages('ggthemes')
# install.packages('patchwork')
```

```{r libraries}
library(tidyverse)
library(bold)
library(Biostrings)
library(ape)
library(DECIPHER)
library(phangorn)
library(dendextend)
library(ggdendro)
library(rcartocolor)
library(ggthemes)
library(patchwork)
```

------

### 1. Introduction

<!-- 
Paragraph 1: What is the overarching topic you are interested in? Why is this scientifically important and interesting and/or societally relevant?o
 -->

<!-- dkd
Paragraph 2: You can outline what is an important sub-area of research or a gap in knowledge. (As an example, perhaps your broader theme is gene expression analysis, and in paragraph 2 you could narrow in to introduce the importance of statistical choices.)
-->

Phylogenetic analysis is common in biodiversity studies and environmental assessment. However, being a multi-step process and with various methods to choose from and parameters to set, it can be far from clear how to proceed. Not only are there many different phylogenetic marker genes (or combinations thereof) to assess, but also many different types of alignment (nucleic acid or protein, symbolic or structural) and ways to cluster sequences (distance, maximum-parsimony, maximum-likelihood). For distance and maximum-likelihood methods, there are a ton of different models of molecular evolution have been described for calculating pairwise distances between sequences.

Molecular evolution is modeled as a Markov process (*ie*. memoryless) with parameters for the rates of substitution. For example, the naive model, Jukes-Cantor, treats all substitutions as equally likely; Kimura 2-parameter treats transitions and transversions differently; more complex models can parameterize each substitution separately, possibly with each position in the alignment or even branches within the tree treated independently. As there is no way to ascertain the actual substitution events and when they occurred, we need to apply some bias (*eg* parsimony, likelihood, or posterior probability) to evaluate the fit of competing models [@Felsenstein1981, @Posada2001]. While we now have methods to select the model that optimizes whichever criteria we choose, the ideal criteria for distance model selection remains unclear; although, this might not matter  much, as we are not particularly interested in the distances, but rather the phylogenetic inferences that we make based on them[@Abadi2019]. 

<!--
Paragraph 3: What is the specific objective of your study? What kind of study are you performing? What will you d 
-->
In this work, I sought to explore the effect of model choice in phylogenetic analysis. Specifically, I wanted to find out whether different distance models would lead to altered inferences about phylogeny through hierarchical clustering. For this, I selected the family of scale worms Polynoidae, and analyzed their cytochrome c oxidase subunit I sequences. Polynoidae are a large and speciose family of scale worms that have colonized challenging habitats in the deep sea, including sea caves and hydrothermal vents[@Zhang2017a, @Hatch2020a]. Many are symbiotic species are associated with other organisms, even other polychaetes[@Salazar-Vallejo2015]. New species are consistently found in surveys and determining their phylogenetic relationships to known species is of interest[@Norlinder2012]. 



### 2. Data

Polynoidae sequence data were downloaded from the public Barcode of Life Database (BOLD) api on 2020-12-10, using their `bold` package. There were 1847 specimen records for this taxon in the database in total. The data of interest (identifiers, sequences, and taxonomic names) were saved as `polynoid.raw.rds`.

```{r eval=FALSE}
## Download BOLD specimen + seq data for taxon 'Polynoidae'
polynoids <- bold::bold_seqspec(taxon = 'Polynoidae')
polynoids <- polynoids %>%
  select(processid, contains('name'), contains('marker'), nucleotides) %>%
  select(-c(trace_names, phylum_name, class_name, marker_codes))
glimpse(polynoids)
write_rds(polynoids, 'polynoid.raw.rds', compress = 'gz')
```

### 3. Acquisition and selection of data

<!-- 3. Code Section 1 â€“ Data Acquisition, Exploration, Filtering, and Quality Control (25%) -->

```{r tidy and filter}
tidy_bold_data <- function(bold.df, markers){
  # blanks to NA's; strings to factors, except for seqs
  # remove rows missing genus+species names
  bold.df <- bold.df %>%
    mutate(across(where(is.character), ~na_if(.x, ''))) %>%
    mutate(across(where(is.character), as_factor)) %>%
    mutate(nucleotides = as.character(nucleotides))  %>%
    filter(!is.na(genus_name) & !is.na(species_name)) 
  return(bold.df)
}
trim_and_filter_seqs <- function(bold.df, markers, minlen, maxlen, Nthreshold){
  bold.df <- bold.df %>%
    # keep seqs of selected gene; trim N and gaps; 
    # filter to seqs within length range and Ns threshold
    filter(!is.na(nucleotides) & markercode %in% markers) %>%
    mutate(seq = str_remove_all(nucleotides, '\\s|-|^N+|N+$'),
           slen = nchar(seq)) %>%
    filter(slen >= minlen & slen <= maxlen & 
             str_count(seq, 'N')/slen <= Nthreshold)
  return(bold.df)  
}

# read in data & apply filtering steps
polynoids.raw <- read_rds('polynoid.raw.rds')
polynoids.df <- polynoids.raw %>%
  tidy_bold_data() %>%
  trim_and_filter_seqs(markers = 'COI-5P', minlen = 630, maxlen = 680, Nthreshold =  0.02)
# Sample 1 sequence per species for analysis
set.seed(1)
polynoids.sample <- polynoids.df %>%
  group_by(species_name) %>%
  sample_n(1) %>%
  data.frame() %>%
  mutate(seqlabel = paste(genus_name, row_number())) %>%
  mutate(across(where(is.factor), fct_drop)) # drop empty factor levels
```


Only Polynoidae specimens having complete taxonomic information and cytochrome c oxidase I barcode sequences of appropriate length (630-680 bp) and with a low proportion of ambiguous base calls (< or = 2%) were retained. This filtered dataset has `r nrow(polynoids.df)` specimens comprised of `r length(unique(polynoids.df$genus_name))` genera, with `r length(unique(polynoids.df$species_name))`  species in total. For analysis, a single representative was chosen at random for each species.


```{r EDA, fig.height=4, fig.width=6, fig.align='center'}
EDA_plot <- function(bold.df, label) {
  a <- ggplot(bold.df, aes(x = slen)) +
    labs(x = 'Sequence length', subtitle = label) +
    geom_histogram() + geom_rangeframe() + theme_tufte()
  b <- bold.df %>%
    mutate(`% GC` = str_count(seq, '[GC]')/slen*100) %>%
    ggplot(aes(x=`% GC`)) + 
    geom_histogram() + geom_rangeframe() + theme_tufte()
  c <- bold.df %>%
    group_by(genus_name) %>%
    summarize(species = length(unique(species_name))) %>%
    ggplot(aes(x=species)) + 
    xlab('Species per genus') +
    geom_histogram() + geom_rangeframe() +theme_tufte()
  return(a/b/c)
}

A <- EDA_plot(polynoids.df, 'Filtered data') 
B <- EDA_plot(polynoids.sample, 'Sampled data')
A|B
```
__Figure 1__. Exploratory analysis of polynoid *cytochrome c oxidase subunit 1* sequences in the filtered data (left) and in the sample with one sequence per species (right).


```{r include=FALSE}
rm(polynoids.raw, polynoids.df, A, B)
```


Most of the sequences are approximately 660 bp in length and have GC-content between 35-45%. I chose a single sequence at random as a representative for each of the 95  species. 

### 4. Tools for model tests and phylogenetic analysis

Sequence alignments and phylogenetic clustering were done with the package `DECIPHER`[@Wright2016]. Alignments in `DECIPHER` are fast and accurate, though many other good choices are available, including the popular `muscle` and `clustal` algorithms. Many implementations of hierarchical clustering are available in R; I chose to use the `DECIPHER` package because of it's integration of multiple tools needed for this analysis into a handy R package. The `ape` package was used to perform model-specific distance calculations (using `dist.dna`) as well as tree-topology comparisons (with `dist.topo`. Molecular evolution models were tested with `phangorn::modelTest`. For visualizations, I used `ggplot2` for plots, as well as `dendextend` to create dendrograms and tanglegrams. Most of these analyses are explained clearly in the package vignettes (see references), however this work extends those by chaining them together for the comparison of phylogenies with testing and other visualizations.


<!-- Silhouette plots were created with... rpartplot -->

<!-- 4. Main Software Tools Description (1 paragraph) (5%) -->
<!-- 
Provide a short written description (1 paragraph) about the main software tool you will be using to answer your main question. 
Why did you make this choice? What are the expected strengths and weaknesses of the tool you chose? Did you consider any alternatives? Cite the authors of the tool you used (you can cite the package itself plus the relevant associated publication, if available). If you are conducting a methodological project involving a comparison of tools, you might briefly describe two main tools in this section. Otherwise, you will typically describe one main software tool. -->
<!-- Also, in this section, make it clear how you built upon existing vignettes for conducting your project. -->

### 5. Phylogenetic Analysis

<!-- Code Section 2 â€“ Main Analysis (25%) --><!-- explore the impact of methodological choices upon results. --> <!-- max 3 figures -->


```{r align and cluster}
do_alignment <- function(sample.df, names_vector, browse=FALSE, verbose = FALSE){
  # Sequences are formatted and labeled, then any reverse complements we reoriented prior to alignment with default parameters
  seqs <- Biostrings::DNAStringSet(sample.df$seq)
  names(seqs) <- names_vector
  seqs <-  DECIPHER::OrientNucleotides(seqs, verbose = verbose)
  seqs.aligned <- DECIPHER::AlignSeqs(seqs, verbose = verbose)
  if (browse==TRUE){
    BrowseSeqs(seqs.aligned)
    }
  return(seqs.aligned)
}
# perform alignment and hierarchical clusterings
polynoids.align <- do_alignment(polynoids.sample, polynoids.sample$seqlabel)
polynoids.bin <- as.DNAbin(polynoids.align)
```



```{r phangorn model test, message=FALSE}
# need phyDat format for testing (from DNAbin)
polynoids.phy <- as.phyDat(polynoids.bin)
# calculate distance, generate tree, then test
polynoids.dist <- phangorn::dist.ml(polynoids.phy, model='JC69')
polynoids.nj <- NJ(polynoids.dist)
# default seletion of models to test (there are many others too if using model = 'all')
model_test <- phangorn::modelTest(polynoids.phy, polynoids.nj)
glimpse(model_test)
model_test %>% filter(BIC == min(model_test$BIC))
```
```{r message=FALSE, warning=FALSE}
fit <- pml(polynoids.nj, polynoids.phy)
fitJC <-  optim.pml(fit, optNni = TRUE, optBf = TRUE, optQ = TRUE)
fitJC
fitJC <- optim.pml(fitJC, optNni=TRUE, control = pml.control(trace=FALSE))
summary(fitJC)

# create a GTR+I+G model to then perform max likelihood clustering; init value of inv is prior

# JC + Gamma + I - model
fitGTR <- update(fitJC, k=4, inv=.2)
# optimise shape parameter + proportion of invariant sites   
fitGTR <- optim.pml(fitJC_GI, optGamma=TRUE, optInv=TRUE)
# summary(fitGTR) 
# GTR + Gamma + I - model
fitGTR <- optim.pml(fitGTR, optNni=TRUE, optGamma=TRUE, optInv=TRUE, optBf=TRUE, optQ=TRUE) 
# summary(fitGTR)

fitJC
fitGTR
```

<!-- The following models of molecular evolution tested with phangorn: -->
<!-- - JC: One parameter for all substitutions; equal base frequencies (Jukes and Cantor 1969). -->
<!-- - F81: Variable base frequencies, equal substitution rates (Felsenstein 1981) -->
<!-- - GTR: General time-reversible: variable bases, symetric substitution matrix  (Lanave et al. 1984) -->
<!-- - HKY: Hasegawa-Kishino-Yano: One parameter each for transitions and tranversions, with variable base frequencies (Hasegawa et. al. 1985) -->
<!-- - K80: One parameter each for transitions and tranversions, with equal base frequencies (Kimura 1980) -->
<!-- - SYM: Symmetrical substititions with equal base frequencies (Zharkikh 1994) -->



```{r ML clustering with decipher}
## Maximum-likelihood hierarchical clustering
clusters.ML <- DECIPHER::IdClusters(
  myXStringSet = polynoids.align,
  myDistMatrix = DistanceMatrix(polynoids.align, type='dist'),
  method = 'ML', 
  cutoff = 0.2, showPlot = FALSE,
  type = "both", verbose = TRUE)

# Distance-based clustering using Jukes Cantor model
clusters.JC <- DECIPHER::IdClusters(
  myXStringSet = polynoids.align,
  myDistMatrix = dist.dna(x = polynoids.bin, model = 'JC',
             as.matrix = FALSE, pairwise.deletion = TRUE),
  model = 'JC', method = 'NJ',
  cutoff = 0.17, showPlot = FALSE,
  type = "both", verbose = FALSE)
```
Maximum-likelihood clustering was performed and the model selected (having the lowest BIC in this case) was TN93+G, which fit better than the HKY model chosen by the earlier model testing with `phangorn`. Annoyingly, the `phangorn` package does not have an implementation of TN93, while `DECIPHER` does not have an implementation of SYM.

TN93+G4 model parameters:
  - Frequency(A) = 0.249
  - Frequency(C) = 0.218
  - Frequency(G) = 0.170
  - Frequency(T) = 0.364
  - Rate A <-> G = 2.113
  - Rate C <-> T = 4.417
  - Transversion rates = 1
  - Alpha = 0.502

```{r include=FALSE}
rm(polynoids.align)
```

I performed hierarchical clustering with various models (JC, K80, TN93)
I also did a maximum-likelihood clustering of the sequences to compare with the default settings. 

### 6. Figures

<!-- 6. Quality of Visualizations (20%) -->
<!-- Throughout, ensure that your figures are clear and well labeled. Even for simple figures, such as histograms, ensure that you have accurate, informative axis labels. Also, consider readability, visual appeal, and accessibility. Use well-differentiated colours, and avoid relying upon the red-green spectrum to convey scientifically important information. Remember, you can consider using a combination of colour and symbol/pattern to convey your meaning. The grade in this section is based upon quality and novelty, not having the maximum permissible number of figures. You should have a total of 4-6 figures for your project (excluding the bonus section, should you choose to complete that section). -->


```{r model test plot, fig.align='center', fig.height=3.5, fig.width=8}
model_test_plot <- model_test %>%
  select(Model, AICc, BIC, logLik, df)  %>%
  pivot_longer(AICc:df) %>%
  mutate(name = as_factor(name)) %>%
  ggplot() + 
  geom_point(aes(x=Model, y=value, colour = name)) + 
  labs(x = '', y = '') +
  facet_grid(name~., scales = 'free_y') + 
  scale_color_carto_d() +
  theme_light() +
  theme(legend.position = 'none', axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))
# plotted in 6. Results and discussion
model_test_plot
```


```{r model test plot2, fig.align='center', fig.height=3.5, fig.width=4}
model_test_plot2 <- model_test %>%
  select(Model, AICc, BIC, logLik, df) %>%
  pivot_longer(AICc:df) %>%
  mutate(name = as_factor(name),
         score2 = ifelse(Model %in% c('GTR+I+G', 'HKY+I+G'),
                         value, NA),
         name2 = ifelse(Model %in% c('GTR+I+G', 'HKY+I+G'),
                         Model, NA)) %>%
  ggplot() + 
  geom_density(aes(x=value, colour = name)) + 
  # geom_vline(aes(x=score2)) +
  labs(x = '', y = 'density') +
  facet_wrap(~name, ncol=1, scales = 'free') + 
  scale_color_carto_d(palette = 2) +
  theme_light() +theme(legend.position = 'none')
model_test_plot2
```
__Figure 2__. Testing of all DNA substitution models (JC, F81, K80, HKY, TrN, TPM, K81, TIM, TVM, SYM, GTR) with and without added site-specificity (G, I) for the polynoid CO1 sequences, using `phangorn::modelTest`. The AIC, BIC and log likelihood scores (y-axis) are shown for each model (x-axis), where smaller AICc and BIC scores and larger log likelihood scores indicate better fit. The degrees of freedom for each model are included (df). 


```{r tanglegram JC v ML, fig.align='center', fig.width=8, fig.height=6}
get_entang_val <- function(dend1, dend2){
  # gets the entanglement score for two dendrograms
  dend1 <- match_order_by_labels(dend1, dend2) 
  dend.list <- dendlist(dend1, dend2)
  entangle.val <- entanglement(dend.list) # calculate entanglement
  return(entangle.val)
}

make_tanglegram <- function(dend1, dend2, title1, title2){
  # makes a tanglegram from 2 dendrograms after orienting leaves
  dend1 <- match_order_by_labels(dend1, dend2)
  dend.list <- dendlist(
    dend1 %>% set('labels_cex', 0.65) %>% set("branches_lwd", 1),
    dend2 %>% set('labels_cex', 0.65) %>% set("branches_lwd", 1)
    )
  gram <- dend.list %>% 
    # need dendext function here, not phytools
    dendextend::untangle() %>% 
    tanglegram(
      main_left = title1,
      main_right = title2,
      just_one = TRUE,
      columns_width = c(6,2,6),
      left_dendo_mar = c(2, 2, 2, 6),
      right_dendo_mar = c(2, 6, 2, 2),
      # common_subtrees_color_branches = TRUE,
      # common_subtrees_color_lines = TRUE,
      # highlight_distinct_edges = FALSE
      match_order_by_labels = TRUE
      )
}

tang_val_JC_ML <- get_entang_val(clusters.JC[[2]], clusters.ML[[2]])
tang_val_JC_ML
tangle_JC_ML <- make_tanglegram(clusters.JC[[2]], clusters.ML[[2]], 'JC distance based',  'TN93 + G maximum likelihood' )
```

```{r}
library(phylogram)
dend.list <- dendlist(
   phylogram::as.dendrogram.phylo(fitJC$tree) %>%
      set('labels_cex', 0.65) %>% set("branches_lwd", 1),
   phylogram:: as.dendrogram.phylo(fitGTR$tree) %>%
      set('labels_cex', 0.65) %>% set("branches_lwd", 1)
    ) %>%
  dendextend::untangle() %>% 
# Make tanglegram
  tanglegram(
    match_order_by_labels = TRUE,
    just_one = TRUE,
    color_branches = TRUE,
    columns_width = c(6, 1, 6),
    left_dendo_mar = c(2, 2, 2, 6),
    right_dendo_mar = c(2, 6, 2, 2)
  )
```

```{r tanglegram JC v ML2, fig.align='center', fig.width=8, fig.height=6}
dend.list <- dendlist(
    clusters.JC[[2]] %>% set('labels_cex', 0.65) %>% set("branches_lwd", 1),
    clusters.ML[[2]] %>% set('labels_cex', 0.65) %>% set("branches_lwd", 1)
    ) %>%
  dendextend::untangle() %>% 
# Make tanglegram
  tanglegram(
    match_order_by_labels = TRUE,
    just_one = TRUE,
    columns_width = c(6, 1, 6),
    left_dendo_mar = c(2, 2, 2, 6),
    right_dendo_mar = c(2, 6, 2, 2)
  )
```

```{r}
ape::dist.topo(as.phylo(clusters.JC[[2]]),
               as.phylo(clusters.ML[[2]]))
```

<!-- The topological distance is defined as twice the number of internal branches defining different bipartitions of the tips (Robinson and Foulds 1981; Penny and Hendy 1985). Rzhetsky and Nei (1992) proposed a modification of the original formula to take multifurcations into account. -->

<!-- The branch length score may be seen as similar to the previous distance but taking branch lengths into account. Kuhner and Felsenstein (1994) proposed to calculate the square root of the sum of the squared differences of the (internal) branch lengths defining similar bipartitions (or splits) in both trees. -->
<!-- Two methods are available: the one by Penny and Hendy (1985, originally from Robinson and Foulds 1981), and the branch length score by Kuhner and Felsenstein (1994). The trees are always considered as unrooted. -->



### 7. Supplemental 

<!-- Bonus Section (Optional) (5%) -->
<!-- This section can contain whatever you want! This is your chance to do something of interest to you, which is related to your overall topic, but which didnâ€™t fit into the mandatory sections. -->
<!-- An example of a topic that could go here would be benchmarking your analysis for computational speed and/or for accuracy (against comparator tools). Or, you could include supplementary statistical testing (e.g. testing whether your results are sensitive to your analytical choices in your main analysis section). You could also include supplementary visualizations of your choosing. -->
<!-- The maximum length of this section is 2 pages of your final PDF assignment. Any content above the two-page limit for this section will not be graded. This could consist of prose, commented code, statistical results, and/or visualizations (your choice). -->
<!-- Tip: Please note that the credit weighting associated with this section is small. So, I suggest ensuring that you have completed a high-quality project for all of the other sections before preparing anything for this section. -->
<!-- Note: The presence of this section means that a grade for Assignment #5 could hypothetically go above 100% (to a maximum of 105%). However, overall course grades are capped at 100% maximum. -->



```{r supPlot1, fig.height=2.5, fig.width=4, fig.align='center'}
distVector <- function(model, dnabin){
  # return numeric vector of the upper triangle of the distance matrix
  dist <- dist.dna(x = dnabin,
                   model = model,
                   as.matrix = FALSE,
                   pairwise.deletion = TRUE)
  return(as.numeric(dist))
}

# Molecular evolution analysis ----
# create a df with all the distance measures as columns
dist.df <- tibble(model = c('raw','jc69','N', 'k80', 'tn93', 'gg95', 'TS', 'TV')) %>%
  mutate(data = lapply(model, function(x) distVector(x, polynoids.bin))) %>%
  pivot_wider(names_from = 'model', values_from = 'data') %>%
  unnest(cols = raw:TV)

glimpse(dist.df)

# plot p-distance ~ k80 distance
raw_k80.plot <- dist.df %>%
  ggplot(aes(x=k80, y=raw)) + 
  geom_point(alpha = 0.5, size = 0.5, pch = 1) +
  # add diagonal line
  geom_path(
    data = data.frame(x = seq(0, 1, 0.05), y = seq(0, 1, 0.05), group = factor('group')),
    aes(x = x, y = y, group = group), alpha = 0.7, lty = 2) +
  theme_classic() +
  xlim(c(0, 0.72)) +
  ylim(c(0, 0.45)) +
  labs(x = 'K2P distance', y = 'p-distance (raw)',
       subtitle = 'Saturation plot:\n distances of Polychaete CO1 sequences')

# plot transitions and transversions ~ k80 distance
ts_tv.plot <- dist.df %>%
  select(k80, TS, TV) %>%
  # manipulate table into long-form
  pivot_longer(cols=c(TS, TV),
               names_to = 'Substitution', values_to = 'Proportion') %>%
  # create scatterplot w smooth fits
  ggplot(aes(x = k80, y = Proportion, color = Substitution, group = Substitution)) +
  geom_point(size=0.04, alpha = 0.3) +
  geom_smooth(method = 'loess', formula = 'y~x', se=FALSE) +
  theme_classic() +
  scale_color_carto_d('Type') +
  guides(
    colour = guide_legend(override.aes = list(size=5, alpha=1, pch=15))
    ) +
  labs(
    x = 'K2P distance',
    y = 'Substiutions',
    title = '',
    subtitle = 'Transitions and transverions by K2P distance\n in Polynoidae COI sequences'
    )
raw_k80.plot + ts_tv.plot
rm(raw_k80.plot, ts_tv.plot, dist.df)
```

I attempted to align translated sequences, however the results were not impressive. The alignment has several sequences that did not align at all. I suspect that the algorithm could not find the correct reading frame and that to do so would require manually setting the reading frame and trimming sequences to begin at a codon; this did not seem feasible to do within the scope of the project. As such, left this out of the analysis.

```{r eval = FALSE}
# translated alignment performs really poorly
align.translated <- DECIPHER::AlignTranslation(DNAStringSet(polynoids.sample$seq), verbose = FALSE)
# BrowseSeqs(align.translated)
```


Comparing distance-based phylogenies in tanglegrams (JC, K80, TN93)

```{r distance-based phylog tanglegrams, fig.align='center', fig.width=8, fig.height=6}

do_clustering <- function(dnabin, model, threshold, algo){
  # performs h.clustering w chosen model, algorithm, & threshold
  DECIPHER::IdClusters(
    dist.dna(x = dnabin, model = model,
             as.matrix = FALSE, pairwise.deletion = TRUE),
    method = algo, cutoff = threshold, verbose = FALSE,
    showPlot = FALSE, type = "both")
} 

# Clustering by three models JC (jc69), K2P (k80), and TN93
models <- c('jc69', 'k80', 'tn93')
clusters <- lapply(models, function(x) do_clustering(polynoids.bin, x, 0.2, 'NJ'))
names(clusters) <- models
dendros <- lapply(clusters, '[[', 2)
names(dendros) <- models

get_entang_val <- function(dend1, dend2){
  # gets the entanglement score for two dendrograms
  dend1 <- match_order_by_labels(dend1, dend2) 
  dend.list <- dendlist(dend1, dend2)
  entangle.val <- entanglement(dend.list) # calculate entanglement
  return(entangle.val)
}
make_tanglegram <- function(dend1, dend2, title1, title2){
  # makes a tanglegram from 2 dendrograms after orienting leaves
  # dend1 <- match_order_by_labels(dend1, dend2) 
  dend.list <- dendlist(
    dend1 %>% set('labels_cex', 0.55) %>% set("branches_lwd", 1),
    dend2 %>% set('labels_cex', 0.55) %>% set("branches_lwd", 1)
    )
  gram <- dend.list %>% dendextend::untangle() %>% # need dendext function
    tanglegram(
      main_left = title1,
      main_right = title2,
      just_one = TRUE,
      columns_width = c(5,1,5),
      left_dendo_mar = c(2, 2, 2, 4),
      right_dendo_mar = c(2, 4, 2, 2),
      match_order_by_labels = TRUE,
      common_subtrees_color_branches = TRUE,
      highlight_distinct_edges = FALSE) 
}
tang_val_K80_JC <- get_entang_val(dendros[[2]], dendros[[1]])
tang_val_TN93_JC <- get_entang_val(dendros[[3]], dendros[[1]])
tang_val_K80_TN93 <- get_entang_val(dendros[[2]], dendros[[3]])
par(mfrow = c(1,3))
tangle_K80_JC <- make_tanglegram(dendros[[2]], dendros[[1]], 'K80','JC')
tangle_TN93_JC <- make_tanglegram(dendros[[3]], dendros[[1]], 'TN93', 'JC')
tangle_K80_TN93 <- make_tanglegram(dendros[[2]], dendros[[3]], 'K80', 'TN93')

# library(phytools)

class(dendros[[1]])
names(dendros)
phylos <- lapply(dendros, as.phylo)
# phylos <- phytools::as.multiPhylo(phylos[[1]], phylos[[2]], phylos[[3]])
# class(phylos)
RH_JC_k80 <- ape::dist.topo(phylos[[1]], phylos[[2]], method = 'PH85')
RH_JC_tn93 <- ape::dist.topo(phylos[[1]], phylos[[3]], method = 'PH85')
RH_k80_tn93 <- ape::dist.topo(phylos[[2]], phylos[[3]], method = 'PH85')
score_JC_k80 <- ape::dist.topo(phylos[[1]], phylos[[2]], method = 'score')
score_JC_tn93 <- ape::dist.topo(phylos[[1]], phylos[[3]],  method = 'score')
score_k80_tn93 <- ape::dist.topo(phylos[[2]], phylos[[3]],  method = 'score')
```

### 8. Results and Discussion

A model that treats each substitution differently is more likely to accurately represent evolutionary processes; for example, cytosine deamination, leading to a C to T substitution, is particularly common. However, parameter estimates from maximum likelihood optimization will have greater error as the number of parameters increases. This may be important to consider if the number of sequences is small and parameter estimates are not as precise. In the TN93 model chosen in ML clustering of polynoid CO1 sequences, the estimate for C-T transitions (4.5) was more than double that of A-G transitions (2.1)



In the model test using `phangorn` however, the HKY+G+I model had the lowest Aikake information criterion with correction for small samples (AICc) and Bayes information criterion (BIC), as well as the greatest log likelihood. Overall, the inclusion of the variation among sites (+G), and static sites (+I) into the model had more impact that differences between substitution models.

Augmented models account for the substitution rate variance among sites: '+G' indicates inclusion of gamma-distributed rate variation among sites; '+I' allows for a proportion of static sites.

Using the `dist.topo` metric (from `ape`) to compare tree by their topological distances (ie. Robinson-Foulds distance), I found that the JC and TN93 models produced the most similar trees (dist = `r topodist_JC_tn93`), while K2P and TN93 models produced the most disparate trees (dist = `r topodist_k80_tn93`). Branch-length scoring produced similar results.





<!-- Result + Discussion section: -->
<!-- 8 -->
<!-- o Paragraph 1: Return to your original question. What is the answer to your question? What did you discover? Were your results as expected or not? -->
<!-- o Paragraph 2: Briefly describe any key caveats of your study. For example, are the conclusions that can be drawn limited by sample size or any other concerns? Were there biases in data availability that could have impacted your project? -->
<!-- o Paragraph 3: What would be the next steps for this research? What would you do next if you had more time and if you were going to develop this work into a larger project? Did your results reveal any interesting preliminary findings that would be worthy of follow-up study? -->
<!-- Guidelines: Please see introduction for length guidelines for written paragraphs. -->
<!-- Tip: I suggest that you consider citing 2-4 references in your discussion section to help with interpretation of your results. You may cite references that you also cited in your introduction. -->
<!-- Tip: At the end, I also encourage you to add an additional short paragraph reflecting upon the process of completing this assignment. What did you learn through completing your project? What lessons will you take forward in your future coursework and career? Reflection can help us to solidify our learning and help us to act upon what we have learned in the future. This additional, optional paragraph is not included in the 3-paragraph length limit for this section. -->


<!-- 9. Acknowledgements (section expected to be present for academic integrity) -->
<!-- If you received project tips from others, include that information in this section. Briefly, indicate who you talked to, the nature of the advice, and how this impacted your project. You may speak to other class members and the course instructors. It is NOT permitted to complete the assignment for someone else or to copy/paste blocks of code from others. If someone helped you to get unstuck when you were facing an error message, then indicate who and what you learned from this. (To clarify: You ARE allowed to talk to others, but you are NOT permitted to let them fix the problem for you without you actually understanding what is going on. Write about: What was causing the error message, and what did you learn during the process of obtaining help to fix it?) -->


<!-- 10. References (grade credit for this section is incorporated into Intro and Discussion grades) -->
<!-- If you cite any sources from the scientific literature, include them here in your reference list. In total for Assignment #5, I suggest consulting and citing 3-6 papers from the literature to help you to develop your idea and/or interpret your results. Ten papers from the literature is the hard maximum for citations, reflecting that you have other assignments and commitments and to encourage some academics/life balance. You may use any of the papers posted to CourseLink or other literature relevant for your project. Additional citations for vignettes, other tutorials, -->
<!-- 9 -->
<!-- StackOverflow posts, etc., are not included in the 10-reference limit. You must cite all such sources. -->
<!-- You would include scientific references as an in-text citation in the relevant sentence of your assignment, i.e. introduction or discussion (e.g. Xu et al. 2020). Also, list the full reference here at the end. If you used any specific online tutorials or a specific StackOverflow posting, for example, you must also include those here. -->
<!-- You should choose a consistent format for your reference list. If you do not already have a preferred format, then I recommend using a simple format such as the following (which includes authors, year, article title, journal name, volume, and page numbers). Your reference list should be ordered by the last name of the first author of each article. Example: -->
<!-- Smith AB, Jones CD, and Zhou EF. 2019. The title of the journal article goes here. Journal Name Goes Here, 25: 131-140. -->




#### Silhouette\
Calculate silhouette index to evaluate internal validity
```{r Silhouette Index, results = "hold"}
# #Calculate Silhouette summary for gene1
# silhouette_gene1 <- silhouette (unlist(gene1_clusters[[1]]),dmatrix = gene1_matrix)
# summary.silhouette_gene1<-summary(silhouette_gene1)
# #Output silhouette summary
# sprintf("Silhouette summary for %s",gene1)
# summary.silhouette_gene1
```

Plot Silhouette Analysis
```{r Silhouette Plot, results = "hold"}
# #Plot silhouette scores for gene1
# fviz_silhouette(silhouette_gene1, label=FALSE,print.summary=TRUE,xlab="Cluster",main=sprintf("Silhouette Analysis for Clustering on %s Nucleotide Sequences", gene1),submain=sprintf("Clustering Method: %s; Model of DNA Evolution: %s",clustering.method,chosen.model),palette=c("#660000","purple","orange","blue"))
```



### 9. Acknowledgements

In preparing this work, I found the following tutorials most helpful:

[The art of multiple sequence alignment in R by E.S. Wright](https://www.bioconductor.org/packages/release/bioc/vignettes/DECIPHER/inst/doc/ArtOfAlignmentInR.pdf)

[Introduction to `dendextend` by T. Galili](https://cran.r-project.org/web/packages/dendextend/vignettes/dendextend.html)

[Estimating phylogenetic trees with phangorn by K.P. Schliep](https://cran.r-project.org/web/packages/phangorn/vignettes/Trees.pdf)

[Genetic data analysis using R: introduction to phylogenetics by T. Jombart](http://adegenet.r-forge.r-project.org/files/MRC-session2-tuto.1.3.pdf)

The chapter 'Phylogeny Estimation' in  "Analysis of Phylogenetics and Evolution with R" by the `ape` author E. Paradis (available through the Guelph library), was particularly helpful in understanding basic aspects of distance-based and maximum likelihood methods.

Last but not least, I would like to thank Dr. Sarah Adamowicz and Jacqueline May for the advice and support they provided, and my 6210 classmates for various inspirations.


### 10. References

<!-- references automatically inserted here from the bib file `polynoid_refs.bib` -->










```{r modify dendrograms, include=FALSE, fig.height=6}
fix_dendrogram <- function(dendro, template){
  dendro <- dendro %>%
    match_order_by_labels(., template) %>%
    set('labels_cex', 0.6) %>%
    set("branches_lwd", 0.5)
  dendro <- as.ggdend(dendro)
}
dendrograms <- lapply(dendros, fix_dendrogram, dendros[[1]])
# par(mfrow=c(1,3))
lapply(dendrograms, ggplot, horiz=TRUE)
```



```{r include=FALSE}
# k80
x <- dendros[[2]] %>% set('labels_cex', 0.7) %>% set("branches_lwd", 1)
# JC69
y <- dendros[[1]] %>% set('labels_cex', 0.7) %>% set("branches_lwd", 1)
dend_diff(x,y) 
```
